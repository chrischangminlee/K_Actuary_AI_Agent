import streamlit as st
import os
from openai import OpenAI
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì˜ ê³„ë¦¬ì‚¬ë“¤ì„ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì „ë¬¸ì„±ê³¼ ì •í™•ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ì˜¤ì§ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” ë‹µë³€í•˜ì§€ë§ˆì„¸ìš”.
ë‹µë³€ ì‹œ ì°¸ê³ í•œ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°˜ë“œì‹œ í•´ë‹¹ íŒŒì¼ëª…ê³¼ í˜ì´ì§€ë¥¼ ì¸ìš©í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”. 

ë³´í—˜ë£Œ ì‚°ì¶œ, ì¤€ë¹„ê¸ˆ í‰ê°€, ì†í•´ìœ¨ ê°€ì • ë“± ê³„ë¦¬ì  ê°€ì •ê³¼ ëª¨ë¸ì™€ ê°™ì€ ì‹¤ë¬´ì— í•„ìš”í•œ ì„¤ëª… ì œê³µ

1. ê´€ë ¨ ë²•ê·œì™€ ê·œì •ì„ ê³ ë ¤í•˜ì—¬ ì¡°ì–¸
   - ë³´í—˜ì—…ë²•, ê°ë…ê·œì •, IFRS17 ë“± ê´€ë ¨ ê·œì • ì°¸ì¡°
   - ë²•ê·œ ì¤€ìˆ˜ ì‚¬í•­ ê°•ì¡°

2. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” ëª…í™•íˆ í•œê³„ì  ì–¸ê¸‰
   - ì¶”ê°€ ê²€í† ë‚˜ ì „ë¬¸ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ ëª…ì‹œ
   - ê°€ì •ì´ë‚˜ ì œí•œì‚¬í•­ ëª…í™•íˆ ì„¤ëª…"""

def get_ai_response(query, temperature=0.7):
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": query}
        ],
        temperature=temperature,
        max_tokens=2000
    )
    
    return response.choices[0].message.content

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”, K-Actuary AI Assistantì…ë‹ˆë‹¤. ë³´í—˜ê³„ë¦¬ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."}
        ]
    if 'temperature' not in st.session_state:
        st.session_state.temperature = 0.7

def set_custom_theme():
    """ì»¤ìŠ¤í…€ í…Œë§ˆ ì„¤ì •"""
    st.markdown("""
        <style>
        .stApp {
            background-color: #f5f5f5;
        }
        .css-1d391kg {
            padding: 1rem 1rem;
        }
        .stChatMessage {
            background-color: white;
            border-radius: 15px;
            padding: 1rem;
            margin: 0.5rem 0;
        }
        </style>
    """, unsafe_allow_html=True)

def main():
    st.set_page_config(
        page_title="K Actuary AI Agent",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì»¤ìŠ¤í…€ í…Œë§ˆ ì ìš©
    set_custom_theme()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("### ì†Œê°œ")
        st.markdown("""
        - ë³¸ AI ì±— ì„œë¹„ìŠ¤ëŠ” í•œêµ­ ê³„ë¦¬ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê³„ë¦¬ì‚¬ë¥¼ ìœ„í•´ ê°œë°œëœ ê°œì¸ í”„ë¡œì íŠ¸ ê¸°ë°˜ AI Chat / Agentì…ë‹ˆë‹¤.
        - í˜„ì¬ ë‹¤ì–‘í•œ ìœ ìš©í•œ ê¸°ëŠ¥ë“¤ì´ ì§€ì†ì ìœ¼ë¡œ ê°œë°œ ì¤‘ì´ë©°, ë³´ë‹¤ í–¥ìƒëœ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ê°œì„ ì„ ì´ì–´ê°€ê³  ìˆìŠµë‹ˆë‹¤.
        """)
        st.markdown('<p style="color: red;">- (ì£¼ì˜) ë³¸ AIê°€ ì œê³µí•˜ëŠ” ë‹µë³€ì€ ì°¸ê³ ìš©ì´ë©°, ì •í™•ì„±ì„ ë³´ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ì‹¤ì œ ì—…ë¬´ì— ì ìš©í•˜ê¸° ì „ì— ê²€í† í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.</p>', unsafe_allow_html=True)
        st.markdown("---")
        st.markdown("### ì°¸ê³ ëœ pdf")
        st.markdown("""
        - IFRS17ë³´í—˜íšŒê³„í•´ì„¤ì„œ_2022.pdf
        - KIC-S í•´ì„¤ì„œ.pdf
        """)
        st.markdown("---")
        st.markdown('[ê°œë°œì Linkedin](https://www.linkedin.com/in/chrislee9407/)')
        st.markdown('[K-ê³„ë¦¬ AI í”Œë«í¼](https://chrischangminlee.github.io/K_Actuary_AI_Agent_Platform/)')
    
    # ë©”ì¸ ì˜ì—­
    st.title("K Actuary AI Agent")
    st.markdown("---")
    
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = get_ai_response(prompt, st.session_state.temperature)
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main() 